+p_xml: 'version="1.0" encoding="UTF-8" standalone="yes" '
+directive: DOCTYPE bugzilla SYSTEM "http://bugzilla.fieldtriptoolbox.org/page.cgi?id=bugzilla.dtd"
bugzilla:
  +@version: 4.4.1
  +@urlbase: http://bugzilla.fieldtriptoolbox.org/
  +@maintainer: r.oostenveld@donders.ru.nl
  bug:
    bug_id: "2134"
    creation_ts: 2013-04-24 15:47:00 +0200
    short_desc: 'ft_pre/postamble_provenance: find alternative for calculating hash'
    delta_ts: 2019-04-02 13:46:36 +0200
    reporter_accessible: "1"
    cclist_accessible: "1"
    classification_id: "1"
    classification: Unclassified
    product: FieldTrip
    component: core
    version: unspecified
    rep_platform: PC
    op_sys: Windows
    bug_status: NEW
    resolution:
    bug_file_loc:
    status_whiteboard:
    keywords:
    priority: P3
    bug_severity: normal
    target_milestone: '---'
    everconfirmed: "1"
    reporter:
      +content: roemer.van.der.meij
      +@name: Roemer van der Meij
    assigned_to: fieldtriptoolbox
    cc: j.schoffelen
    comment_sort_order: oldest_to_newest
    long_desc:
      - +@isprivate: "0"
        commentid: "10286"
        comment_count: "0"
        who:
          +content: roemer.van.der.meij
          +@name: Roemer van der Meij
        bug_when: 2013-04-24 15:47:14 +0200
        thetext: |-
          Right now, input/output data is identified by a unique md5 hash based on all data (except data.cfg's). In order to do this, the data is first 'serialized' into a separate variable, i.e. getting all the bytes that form the data into a linear (contiguous) representation. The is necessary for calculating the md5 hash using CalcMD5, a function from the matlab file exchange.

          This causes several problems:
          1) CalcMD5 cannot handle input bigger than 2^31 bytes, meaning we don't have hashes for big input
          2) this serialization causes short memory spikes, as the data is temporarily re-represented

          Problem 1 could possibly be solved easily by searching for another function to calculate the hash (perhaps also on the file-exchange).

          Problem 2 is more difficult. We discussed this a little in the meeting (24-4-13), where it was suggested to calculate the hash on a part of the data (hopefully enough to get a unique stable identifier). However, the problem with this approach is that it is data-type specific. Another option brought forward was to maybe 'sub-serialize', i.e. only get every other byte, or every 10th byte for that matter.
      - +@isprivate: "0"
        commentid: "19689"
        comment_count: "1"
        who:
          +content: j.schoffelen
          +@name: Jan-Mathijs Schoffelen
        bug_when: 2019-04-02 13:46:36 +0200
        thetext: |-
          https://nl.mathworks.com/matlabcentral/fileexchange/31272-datahash

          https://nl.mathworks.com/matlabcentral/fileexchange/25921-getmd5
