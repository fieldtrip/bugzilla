+p_xml: 'version="1.0" encoding="UTF-8" standalone="yes" '
+directive: DOCTYPE bugzilla SYSTEM "http://bugzilla.fieldtriptoolbox.org/page.cgi?id=bugzilla.dtd"
bugzilla:
  +@version: 4.4.1
  +@urlbase: http://bugzilla.fieldtriptoolbox.org/
  +@maintainer: r.oostenveld@donders.ru.nl
  bug:
    bug_id: "2977"
    creation_ts: 2015-10-05 16:14:00 +0200
    short_desc: datset unusable after call of ft_definetrial
    delta_ts: 2019-08-10 12:31:27 +0200
    reporter_accessible: "1"
    cclist_accessible: "1"
    classification_id: "1"
    classification: Unclassified
    product: FieldTrip
    component: fileio
    version: unspecified
    rep_platform: PC
    op_sys: Linux
    bug_status: CLOSED
    resolution: INVALID
    bug_file_loc:
    status_whiteboard:
    keywords:
    priority: P5
    bug_severity: major
    target_milestone: '---'
    everconfirmed: "1"
    reporter:
      +content: a.wollbrink
      +@name: Andreas Wollbrink
    assigned_to: fieldtriptoolbox
    cc:
      - eelke.spaak
      - r.oostenveld
    comment_sort_order: oldest_to_newest
    long_desc:
      - +@isprivate: "0"
        commentid: "16166"
        comment_count: "0"
        who:
          +content: a.wollbrink
          +@name: Andreas Wollbrink
        bug_when: 2015-10-05 16:14:42 +0200
        thetext: "after calling ft_definetrial (see below) the used data set seems to be modified and no longer usable afterwards (see below)\n\nprogram snip used:\n\n############## BEGIN of code #########################################\n% split raw data into epochs\ncfg = [];\ncfg.dataset                 = 'Test_tDCScharge_20151005_01.ds';\ncfg.continuous              = 'yes';\ncfg.trialdef.eventtype      = 'refDipPeak';\ncfg.trialdef.prestim        = 0.0;\ncfg.trialdef.poststim       = 6.0;\n\ncfg = ft_definetrial(cfg);\n############# END of code\n\n\nwhen one resuses the same snip (or any other fieldtrip function) the error is as follows:\n\nError using ft_read_header (line 2056)\nunsupported header format (unknown)\n\nchecking the status of the datset with (CTF program) dshead it gives an error message 'dshead: unhandled exception.'. The dataset seems to be out of order.\n\n\nwhen one runs the program snip above you get the following warning message:\n\nWarning: '/data/biomag01/Bachelorarbeit-WillemMueller/tDCS-charge/Honigmelone2015Oct05/Test_tDCScharge_20151005_01.ds' is a directory.  Use rmdir to delete directories. \n> In ft_read_header (line 2142)\n  In ft_read_event (line 498)\n  In ft_trialfun_general (line 87)\n  In ft_definetrial (line 174)\n\n\nhaving a closer look to the functions used I realized there seems to be a malfunction in ft_read_header:\n\neven not using a compressed data file the function ft_read_header assumes to be one, inflates it and tries to delete the original file"
      - +@isprivate: "0"
        commentid: "16167"
        comment_count: "1"
        who:
          +content: a.wollbrink
          +@name: Andreas Wollbrink
        bug_when: 2015-10-05 16:15:50 +0200
        thetext: 'I forget to mention the Fieldtrip version used: version r10622'
      - +@isprivate: "0"
        commentid: "16168"
        comment_count: "2"
        who:
          +content: eelke.spaak
          +@name: Eelke Spaak
        bug_when: 2015-10-05 16:21:39 +0200
        thetext: "(In reply to Andreas Wollbrink from comment #1)\nHi Andreas, I believe this bug was fixed in revision 10623 (so you are *just* one revision behind the fix, unfortunately):\n\nr10623 | roboos | 2015-08-24 22:13:31 +0100 (Mon, 24 Aug 2015) | 2 lines\n\nbugfix - fixed serious bug that I introduced in the previous revision 10622. The bug caused certain (multi-file format) datasets to have the data or header file deleted, e.g. the meg4 file in a ds directory would be deleted due to an incorrect detection of the dataset being unzipped to a temporary directory. Another affected format is brainvision (with the vhdr/vmrk/dat files). I noticed since a lot of the test files suddenly went missing. \n\nHopefully this did not cause you to lose any data!"
      - +@isprivate: "0"
        commentid: "16171"
        comment_count: "3"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-10-05 21:55:15 +0200
        thetext: "(In reply to Eelke Spaak from comment #2)\n\nHi Andreas,\n\nSorry for the really stupid bug. It was my fault and the bug only existed for ~12 hours. Is there a specific reason why you might be stuck on this particular revision of fieldtrip?\n\nI can think of a potential reason for you (still) having this problem: I think it was the last revision that made it to googlecode (i.e. svn on google) before google discontinued the googlecode service. If you had been doing svn update from googlecode and are still doing it, it might be that you are getting an error (which you might not notice if it is in a cron job) or it might be that there is no clear error at all, just no update any more. \n\nbest\nRobert"
      - +@isprivate: "0"
        commentid: "16184"
        comment_count: "4"
        who:
          +content: a.wollbrink
          +@name: Andreas Wollbrink
        bug_when: 2015-10-06 17:13:20 +0200
        thetext: |-
          Hi Robert,

          indeed I still used the googlecode svn update feature.

          After switching to github I was able to download a new version of fieldtrip (version 4c881c0e054ce2e22f072302463b58a2334cb32e).

          The bug seems to be fixed.

          Fortunately I was working on a copy of my dataset. Therefore I did not loose any data.

          Thanks for your support.

          Cheers,
          Andreas
      - +@isprivate: "0"
        commentid: "20109"
        comment_count: "5"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2019-08-10 12:31:27 +0200
        thetext: "This closes a whole series of bugs that have been resolved (either FIXED/WONTFIX/INVALID) for quite some time. \n\nIf you disagree, please file a new issue on https://github.com/fieldtrip/fieldtrip/issues."
