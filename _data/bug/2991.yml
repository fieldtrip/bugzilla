+p_xml: 'version="1.0" encoding="UTF-8" standalone="yes" '
+directive: DOCTYPE bugzilla SYSTEM "http://bugzilla.fieldtriptoolbox.org/page.cgi?id=bugzilla.dtd"
bugzilla:
  +@version: 4.4.1
  +@urlbase: http://bugzilla.fieldtriptoolbox.org/
  +@maintainer: r.oostenveld@donders.ru.nl
  bug:
    bug_id: "2991"
    creation_ts: 2015-10-21 20:29:00 +0200
    short_desc: implement support for the *.besa file format
    delta_ts: 2019-08-10 12:32:31 +0200
    reporter_accessible: "1"
    cclist_accessible: "1"
    classification_id: "1"
    classification: Unclassified
    product: FieldTrip
    component: external_besa
    version: unspecified
    rep_platform: PC
    op_sys: Mac OS
    bug_status: CLOSED
    resolution: FIXED
    bug_file_loc:
    status_whiteboard:
    keywords:
    priority: P5
    bug_severity: normal
    target_milestone: '---'
    everconfirmed: "1"
    reporter:
      +content: r.oostenveld
      +@name: Robert Oostenveld
    assigned_to:
      +content: a.stolk8
      +@name: Arjen Stolk
    cc:
      - a.stolk8
      - Harald.Bornfleth
      - kla
      - rspangler
    comment_sort_order: oldest_to_newest
    long_desc:
      - +@isprivate: "0"
        commentid: "16234"
        comment_count: "0"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-10-21 20:29:34 +0200
        thetext: "Hi Todor,\n\nWe came across some external users with ECoG data from Nihon Koden that is stored in the *.besa file format. It seems that FieldTrip does not support this yet. \n\nDo you happen to have a MATLAB reader that you could share?\n\nthanks\nRobert"
      - +@isprivate: "0"
        commentid: "16347"
        comment_count: "1"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-11-12 13:32:20 +0100
        thetext: "I had some email exchange with BESA and received this\n\nOn 12 Nov 2015, at 13:25, Robert Spangler wrote:\n\nWe decided to publish the file format description for our BESA format (*.besa). Furthermore, we are really interested in providing MATLAB routines to import/export *.besa files from BESA to Fieldtrip and vice versa, however we do not have the possibility to achieve this task since our developers are fully occupied at the moment. In case one of your users, or maybe one of your developers would be willing to start implementing these routines, we will provide all the support they need.\n \nThe file format description can be downloaded from the link below:\nhttp://www.besa.de/downloads/file-formats/\n\n@Arjen, I guess it is up to us to act upon this."
      - +@isprivate: "0"
        commentid: "16348"
        comment_count: "2"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-11-12 13:36:36 +0100
        thetext: |-
          (In reply to Robert Oostenveld from comment #1)

          I had a quick look at the documentation. The documentation is well written in terms of details. Although it looks complex, the overall file format is not that hard since it is a "tagged file format" with blocks, each block with a mini header (with the ID and size) and the data. Decoding the structure of the file therefore is easy, decoding the content of (some of the) blocks will be more difficult.
      - +@isprivate: "0"
        commentid: "16356"
        comment_count: "3"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-11-14 05:44:57 +0100
        thetext: |-
          Hi guys, I'm working on a Matlab importing script and have some questions concerning the documentation. Any idea how I could get in touch with someone at BESA for more info?

          1 - Section 2.3 (CHNU) - An array of what kind of integers (int16, int32)?

          2 - Section 2.3 (CHLS) - "If a non-positive value is found in the array, a value of "1.f" is used instead". Is 'f' the value just read, so the result would be something like 1.0 plus f divided by the minimum power of 10 greater than f?
            - Also, LSB does not affect floats (compressed or uncompressed), but does affect compressed int16s, correct?

          3 - Section 2.3 (CHCU) - "Stored as an array <number of channels (CHNR)> series of 2-byte characters.". Just one character per channel, then?

          4 - Section 2.3 (CHCM) - Same as above

          Lastly, I only have test data from a particular system that does not include many of the possible fields (events, most channel info, etc) in the file. The data I'm working with is not compressed, either. So far the script can read these files fine, but I'd like to make  it work with all .besa files, generally. Could I possibly get some sample files from someone with a besa license? I'd be happy to share the finished script with BESA and fieldtrip.

          Thanks so much for getting documentation for the file format. I've been using an undocumented .exe file to convert from .besa to .edf before any analyses and having a way to directly convert will save a lot of time and space.
      - +@isprivate: "0"
        commentid: "16359"
        comment_count: "4"
        who:
          +content: tjordanov
          +@name: Todor Jordanov
        bug_when: 2015-11-16 09:34:18 +0100
        thetext: |-
          Hi Kris,

          the specialist responsible for the besa file format is Robert Spangler (rspangler@besa.de). Please feel free to contact him for any questions about the format.
      - +@isprivate: "0"
        commentid: "16360"
        comment_count: "5"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2015-11-16 09:37:10 +0100
        thetext: |-
          (In reply to Todor Jordanov from comment #4)
          Hi Todor,
          Do you think you could get Robert to join this chat, such that we too can think along?
          Yours,
          Arjen
      - +@isprivate: "0"
        commentid: "16363"
        comment_count: "6"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-11-16 10:12:59 +0100
        thetext: |-
          (In reply to Arjen Stolk from comment #5)

          Robert Spangler is CCed on this bugzilla thread, so he is automatically receiving emails that relate to this.
      - +@isprivate: "0"
        commentid: "16367"
        comment_count: "7"
        who:
          +content: rspangler
          +@name: Robert Spangler
        bug_when: 2015-11-16 11:19:59 +0100
        thetext: "Hey Kris,\n\nIf you have any question regarding the file format, just post them here. I am CCed to this thread.\n\nIn your recent post you asked:\n\n1 - Section 2.3 (CHNU) - An array of what kind of integers (int16, int32)?\nThis is an int16 array storing a unique number for each channel.\n\n2 - Section 2.3 (CHLS) - \"If a non-positive value is found in the array, a value of \"1.f\" is used instead\". Is 'f' the value just read, so the result would be something like 1.0 plus f divided by the minimum power of 10 greater than f?\n  - Also, LSB does not affect floats (compressed or uncompressed), but does affect compressed int16s, correct?\nThis value is only set if int16 data are written in the data blocks and was to convert the float values to int16 values during writing the data. For reading you need to multiply the int16 values in order to get the float values again:\nfloat value = int16*LSB\nIf data are stored as float values, you can ignore this section.\n\n3 - Section 2.3 (CHCU) - \"Stored as an array <number of channels (CHNR)> series of 2-byte characters.\". Just one character per channel, then?\nNo, it can be multiple characters per channel, separated by '\\0'.\nE.g.: \nmV\\0µV\\0nV\\0\n->\nChannel 1: mV\nChannel 2: µV\nChannel 3: nV\n\n4 - Section 2.3 (CHCM) - Same as above\nYes, its the same procedure as for CHCU.\nE.g.: \nBad channel\\0Paused during recording\\0Dummy channel\\0My favourite channel\\0\n->\nChannel 1: Bad channel\nChannel 2: Paused during recording\nChannel 3: Dummy channel\nChannel 3: My favourite channel\n\nI can send you some demo data in *.edf and *.besa format if you like (via Dropbox). Or you can give me EDF files  (that contain well defined characteristics) and I will convert them to *.besa. So you can do unit tests after reading both files.\n\nCheers,\nRobert"
      - +@isprivate: "0"
        commentid: "16368"
        comment_count: "8"
        who:
          +content: rspangler
          +@name: Robert Spangler
        bug_when: 2015-11-16 11:23:28 +0100
        thetext: |-
          Sorry. Just found a typo after submission:

          1 - Section 2.3 (CHNU) - An array of what kind of integers (int16, int32)?
          This is an int32 array storing a unique number for each channel.

          Robert
      - +@isprivate: "0"
        commentid: "16377"
        comment_count: "9"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-11-17 01:49:13 +0100
        thetext: |-
          Thanks Robert,

          Here is a dropbox link to a .bdf file:

          https://www.dropbox.com/sh/cpi4fidcceuvzlt/AADj2IobeRvDS1wfLuTIu_6Wa?dl=0

          Could you convert this to both a compressed and uncompressed .besa format?
      - +@isprivate: "0"
        commentid: "16381"
        comment_count: "10"
        who:
          +content: rspangler
          +@name: Robert Spangler
        bug_when: 2015-11-17 15:53:45 +0100
        thetext: |-
          Hey Kris,

          I converted the *.bdf file using 3 different types of compression:
          - no compression
          - maximum compression
          - fast compression
          Output data was written as float arrays.
          Please note that I did not convert any events, since there seems to be an issue with one of the events. Have to look at the implementation of our BDF reader to check what is happening there.

          You can download the files here:
          https://www.dropbox.com/sh/0maxgeeyxzei1cf/AACxvfGsQv9YzA4ZVheQ3fKva?dl=0

          Robert
      - +@isprivate: "0"
        commentid: "16383"
        comment_count: "11"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-11-17 17:28:25 +0100
        thetext: "(In reply to Robert Spangler from comment #10)\n\nthanks for making progress on this. \n\nFor my own reference (and for eventual including in the Donders FT testing framework): I hope copied the files to /home/common/matlab/fieldtrip/data/test/bug2991"
      - +@isprivate: "0"
        commentid: "16403"
        comment_count: "12"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-11-22 02:06:35 +0100
        thetext: |-
          In section 3.1.2.5, values for the prefix byte of various pre-compression schemes are defined. Is it possible that some schemes might be missing?

          I am stuck at the moment with a prefix value of 18 at one point in the (compressed) data. Everything up to that looks as expected.

          I just thought I'd ask because it looks like some possible scenarios aren't covered:
           - Second Scheme + first 2 entries int
           - Third Scheme + first 2 entries int
           - zlib on Second Scheme + first 2 entries int
           - zlib on Third Scheme + first 2 entries int
      - +@isprivate: "0"
        commentid: "16404"
        comment_count: "13"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-11-22 23:44:49 +0100
        thetext: After going through the data, it appears that prefix 18 means zlib on Second Scheme + first 2 entries int.
      - +@isprivate: "0"
        commentid: "16405"
        comment_count: "14"
        who:
          +content: rspangler
          +@name: Robert Spangler
        bug_when: 2015-11-23 12:13:06 +0100
        thetext: |-
          There are two entries missing in the list:
          18: zlib on Second Scheme + first 2 entries int
          19: zlib on Third Scheme + first 2 entries int

          The following two options are not possible:
           - Second Scheme + first 2 entries int
           - Third Scheme + first 2 entries int

          Prefix byte values that are not mentioned in the file format description (1, 2, 10-12, 16, 20-28) are not used and could be handled by returning an error.

          The file format description will be updated accordingly!
      - +@isprivate: "0"
        commentid: "16423"
        comment_count: "15"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-11-23 22:56:20 +0100
        thetext: Okay, these files are being read correctly. Could you upload a sample file with events? It doesn't have to match the .bdf I uploaded, just anything containing event blocks.
      - +@isprivate: "0"
        commentid: "16427"
        comment_count: "16"
        who:
          +content: rspangler
          +@name: Robert Spangler
        bug_when: 2015-11-24 12:07:13 +0100
        thetext: |-
          I added a couple of files that include events (triggers, comments, generic events, segment events) to the Dropbox folder:
          https://www.dropbox.com/sh/68c954j1chy2usy/AACa_hdH_7KBNF2j6YWjcVssa?dl=0
      - +@isprivate: "0"
        commentid: "16516"
        comment_count: "17"
        attachid: "760"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-12-09 02:05:34 +0100
        thetext: |-
          Created attachment 760
          Preliminary readbesa matlab function
      - +@isprivate: "0"
        commentid: "16517"
        comment_count: "18"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-12-09 02:35:13 +0100
        thetext: "I've attached the function where I am at so far. \n\nAll of the files can be read except for 'Segment - Generic.besa'. The first block has a prefix byte = 4 (Second scheme) and I am reading a value of 255 outside of an 'announcing byte' section, which is undefined. I've spent some time troubleshooting but can't find the problem. Going to keep trying to figure it out but I thought I'd post an update in the meantime and ask for any insight you guys might have.\n\nSome other notes:\nA) Page 39 Table 2. 'Third a' should have a delta=3, not 2\n\nB) HSPC on Page 21 should be HSPD\n\nC) I'm a little confused about signed vs unsigned values for some elements. DATS on Page 33, for example. It specifies the number of samples written to a block of data, which should always be positive, but the doc says that it is a '32 bit integer value', not 32 bit unsigned integer. More than 2 billion samples is unlikely, but not sure what would happen in that case.\n\nD) There are some tags that are less than four characters described in the Event section (MPS, IMP, NR, VAL). Aren't all tags supposed to be 4 bytes?\n\nE) I don't understand what to do in the case a negative LSB is encountered in the Channel and Location block. Here is what the doc says:\n - If a non-positive value is found in the array, a value of \"1.f\" is used instead.\nWhat would 'f' be in this case?"
      - +@isprivate: "0"
        commentid: "16518"
        comment_count: "19"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-12-09 07:39:11 +0100
        thetext: "(In reply to Kris Anderson from comment #18)\n\n\nHi Kris,\n\nThanks for the great work and progress you made. I have added the format FieldTrip-style to ft_filetype, which returns 'besa_besa' (manufacturer_subformat) and also added some preliminary code to ft_read_header, ft_read_data and ft_read_event.\n\nI am traveling at the moment and don't have test data with me, furthermore I have little time right now. \n\nPerhaps Arjan could have a go at testing it and extending the FT glue in the ft_read_xxx functions.\n\nOne thing I realize to be dealt with is the passing of the data selection to the low level function (so that it can read a selection at a time). It might be that that is difficult to implement. Brute force (i.e. read everything, discard most) would be good enough to start with, then I can implemented the internal caching (read everything, return a small section but keep the rest for the next read call) like I have done it for some other formats. If caching is needed to make it sufficiently efficient to read small segments, then I can implement that (to keep it consistent with the caching for some other formats).\n\nmac011> svn commit\nSending        ft_filetype.m\nSending        ft_read_data.m\nSending        ft_read_event.m\nSending        ft_read_header.m\nAdding         private/read_besa_besa.m\nTransmitting file data .....\nCommitted revision 10985."
      - +@isprivate: "0"
        commentid: "16520"
        comment_count: "20"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2015-12-09 23:03:33 +0100
        thetext: |-
          It shouldn't be too difficult to only read part of the data, because the number of sample points in each data block is specified in the header. Though the minimum amount of data that can be read is one block, and the blocks can technically be any size. In practice they should be manageable.

          I made a separate function that reads the header so that can be read quickly and did a pull request on github.
      - +@isprivate: "0"
        commentid: "16521"
        comment_count: "21"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2015-12-09 23:05:50 +0100
        thetext: |-
          (In reply to Kris Anderson from comment #20)

          Nice work, Kris! As soon as Robert pulls the code in, we can test it out on some of our own previously recorded data.
      - +@isprivate: "0"
        commentid: "16522"
        comment_count: "22"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2015-12-09 23:50:10 +0100
        thetext: |-
          (In reply to Arjen Stolk from comment #21)

          mac011> svn commit

          Sending fileio/private/read_besa_besa.m
          Adding fileio/private/read_besa_besa_header.m
          Transmitting file data ..
          Committed revision 10987.

          I merged the pull request into the original SVN copy, it will automatically end up in git.
      - +@isprivate: "0"
        commentid: "16523"
        comment_count: "23"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2015-12-10 00:19:34 +0100
        thetext: "Thanks, Robert.\n\nCheck 1: reading (supposedly) the same data (a besa file converted to edf). Seems that the header file is not consistent across edf and besa format yet (or reader functions). Will run a few more tests.\n\n>> bhdr = ft_read_header('/Users/arjsto/Documents/Ecog/data/IR29/2015100810_0004.besa')\nehdr = ft_read_header('/Users/arjsto/Documents/Ecog/data/IR29/2015100810_0004.edf')\nWarning: all channels must have unique labels, creating unique labels \n> In ft_read_header (line 2124) \n\nbhdr = \n\n           orig: [1x1 struct]\n         nChans: 168\n             Fs: 5000\n       nSamples: 5363000\n    nSamplesPre: []\n        nTrials: 1\n          label: {168x1 cell}\n       chantype: {168x1 cell}\n       chanunit: {168x1 cell}\n\nWarning: all channels must have unique labels, creating unique labels \n> In ft_read_header (line 2124) \n\nehdr = \n\n             Fs: 5000\n         nChans: 169\n          label: {169x1 cell}\n       nSamples: 5363030\n    nSamplesPre: 0\n        nTrials: 1\n           orig: [1x1 struct]\n       chantype: {169x1 cell}\n       chanunit: {169x1 cell}"
      - +@isprivate: "0"
        commentid: "16530"
        comment_count: "24"
        who:
          +content: rspangler
          +@name: Robert Spangler
        bug_when: 2015-12-14 12:24:02 +0100
        thetext: |-
          (In reply to Kris Anderson from comment #18)
          Hey Chris,

          here are some notes regarding your questions from post #18:

          Some other notes:
          A) Page 39 Table 2. 'Third a' should have a delta=3, not 2
          -> Correct. I updated the document. There is a new version available here: http://www.besa.de/downloads/file-formats/

          B) HSPC on Page 21 should be HSPD
          -> HSPC is used for head surface point coordinates (in mm). HSPD is used for head surface point labels.

          C) I'm a little confused about signed vs unsigned values for some elements. DATS on Page 33, for example. It specifies the number of samples written to a block of data, which should always be positive, but the doc says that it is a '32 bit integer value', not 32 bit unsigned integer. More than 2 billion samples is unlikely, but not sure what would happen in that case.
          -> We also use this integer value internally to return error codes with negative values. Therefore, we chose a signed instead of an unsigned value. I agree that 2 billion samples should cover most of the cases, so a signed integer should be fine.

          D) There are some tags that are less than four characters described in the Event section (MPS, IMP, NR, VAL). Aren't all tags supposed to be 4 bytes?
          -> All tags consist of 4 characters. However, some tags (MPS, IMP, NR, VAL, ...) only use 2 or 3 characters to define the type. Remaining characters are filled with whitespace characters.

          E) I don't understand what to do in the case a negative LSB is encountered in the Channel and Location block. Here is what the doc says:
          - If a non-positive value is found in the array, a value of "1.f" is used instead. What would 'f' be in this case?
          -> This is a C++ statement (the documentation was written by developers). The .f tells the compiler to interpret the literal as a floating point number of type float. Without the .f the number gets interpreted as an integer. In C++ source code we need to do this to get a float value. In Matlab code, you do not have to do anything if the LSB is negative. Just interpret the data you read from file as float values.

          Robert
      - +@isprivate: "0"
        commentid: "16675"
        comment_count: "25"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2016-01-21 01:44:24 +0100
        thetext: |-
          Hi all,

          I modified the read_besa_besa function to match the behavior of read_edf and submitted a pull request:
          https://github.com/fieldtrip/fieldtrip/pull/73

          It looks like EDF is storing an extra channel with event information which BESA doesn't have. Event information is stored in the BESA header.

          Exporting the event information from a .besa file to fieldtrip still needs to be implemented, but continuous files are working.

          Not all compression formats have been tested with this script, so people should be careful using it.
      - +@isprivate: "0"
        commentid: "16676"
        comment_count: "26"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2016-01-21 01:53:38 +0100
        thetext: |-
          (In reply to Kris Anderson from comment #25)
          Great work, Kris. I'll run a couple of tests as soon as Robert pulls your git-request!
      - +@isprivate: "0"
        commentid: "16690"
        comment_count: "27"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2016-01-22 12:31:48 +0100
        thetext: "(In reply to Kris Anderson from comment #25)\n\nThanks. \n\nI made a pull73 branch, merged yours and rebased it to master. Then I did a diff to master to determine the precise patch. Using that patch I patched the latest svn version.\n\nmac011> patch -p1 < ~/Desktop/patch73 \npatching file fileio/ft_filetype.m\npatching file fileio/ft_read_data.m\npatching file fileio/ft_read_header.m\npatching file fileio/private/read_besa_besa.m\npatching file fileio/private/read_besa_besa_header.m\n \nmac011> svn commit \nSending        fileio/ft_filetype.m\nSending        fileio/ft_read_data.m\nSending        fileio/ft_read_header.m\nSending        fileio/private/read_besa_besa.m\nSending        fileio/private/read_besa_besa_header.m\nTransmitting file data .....\nCommitted revision 11104."
      - +@isprivate: "0"
        commentid: "16691"
        comment_count: "28"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2016-01-22 12:32:46 +0100
        thetext: please note that I am making progress with bug 3049 and that full migration from svn to github is getting closer...
      - +@isprivate: "0"
        commentid: "16692"
        comment_count: "29"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2016-01-22 20:22:03 +0100
        thetext: "Thanks both. \n\nRan a couple of quick tests. Apart from a 30 to 40 samples mismatch between EDF and BESA, and EDF adding another (annotation) channel, it seems to be fine. I ran a check to see whether my photodiode event detection produces the same samples-of-interest for both the EDF and BESA files, and it does.\n\nWhat needs to be done still, is to write a wiki page on how to get started with besa in fieldtrip. I have made a start here:\nhttp://www.fieldtriptoolbox.org/getting_started/besa\nCould any of the besa guys and ladies maybe fill in the missing information on the header description (in particular the 'event' information), and background information about the besa company & data format? For an example of the latter, see introduction section of: http://www.fieldtriptoolbox.org/getting_started/edf\nDoesn't have to be that elaborated.\n\nThanks,\nArjen\n\n\n\n\n\nDATASET 1:\n\n>> hdr = ft_read_header([getenv('HOME') '/Projects/Ecog/data/IR30/2015102714_0003.edf' ])\nWarning: all channels must have unique labels, creating unique labels \n> In ft_read_header (line 2135) \n\nhdr = \n\n             Fs: 5000\n         nChans: 191\n          label: {191x1 cell}\n       nSamples: 9719040\n    nSamplesPre: 0\n        nTrials: 1\n           orig: [1x1 struct]\n       chantype: {191x1 cell}\n       chanunit: {191x1 cell}\n\n>> hdr_b = ft_read_header([getenv('HOME') '/Projects/Ecog/data/IR30/2015102714_0003.besa' ])\nWarning: all channels must have unique labels, creating unique labels \n> In ft_read_header (line 2135) \n\nhdr_b = \n\n           orig: [1x1 struct]\n         nChans: 190\n             Fs: 5000\n       nSamples: 9719000\n    nSamplesPre: 0\n        nTrials: 1\n          label: {190x1 cell}\n       chantype: {190x1 cell}\n       chanunit: {190x1 cell} \n\n\nDATASET 2:\n\n>> hdr = ft_read_header([getenv('HOME') '/Projects/Ecog/data/IR29/2015100810_0004.edf' ])\nWarning: all channels must have unique labels, creating unique labels \n> In ft_read_header (line 2135) \n\nhdr = \n\n             Fs: 5000\n         nChans: 169\n          label: {169x1 cell}\n       nSamples: 5363030\n    nSamplesPre: 0\n        nTrials: 1\n           orig: [1x1 struct]\n       chantype: {169x1 cell}\n       chanunit: {169x1 cell}\n\n>> hdr_b = ft_read_header([getenv('HOME') '/Projects/Ecog/data/IR29/2015100810_0004.besa' ])\nWarning: all channels must have unique labels, creating unique labels \n> In ft_read_header (line 2135) \n\nhdr_b = \n\n           orig: [1x1 struct]\n         nChans: 168\n             Fs: 5000\n       nSamples: 5363000\n    nSamplesPre: 0\n        nTrials: 1\n          label: {168x1 cell}\n       chantype: {168x1 cell}\n       chanunit: {168x1 cell}"
      - +@isprivate: "0"
        commentid: "16693"
        comment_count: "30"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2016-01-22 20:42:11 +0100
        thetext: "to all: I realized that we already have a BESA page at\n\nhttp://www.fieldtriptoolbox.org/integrating_with/integrating_with_besa \n\nthat is part of this series\nhttp://www.fieldtriptoolbox.org/integrating_with\nwhich nowadays does not seem to be linked in the menu (and therefore almost impossible to find).\n\nWe should avoid overlap. Actually, I suggest that - now that the \"getting started\" series becomes more and more elaborate - we move all 4 (besa, spm8, eeglab, loreta) to the getting started section and delete the old \"integrating with\" section. The 5th link is to a faq which is also linked from elsewhere."
      - +@isprivate: "0"
        commentid: "16694"
        comment_count: "31"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2016-01-22 21:02:40 +0100
        thetext: "(In reply to Robert Oostenveld from comment #30)\n\nI have merged them, i.e. there is now a single section with links to all the system-specific getting started pages. \n\nhttp://www.fieldtriptoolbox.org/getting_started/shared\n\nThat section is shared by including it in these two pages \n\nhttp://www.fieldtriptoolbox.org/getting_started\nhttp://www.fieldtriptoolbox.org/reading_data\n\nwhere the 1st one is a top-level menu item and the 2nd one is located under \"user documentation -> importing your data\"\n\nI simply merged the old BESA section to the new page. The whole section should be reviewed and cleaned up. Next week I'll be doing an educational session together with Harald (from BESA, now also CC) in Finland and will discuss with him."
      - +@isprivate: "0"
        commentid: "16695"
        comment_count: "32"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2016-01-22 23:12:41 +0100
        thetext: Excellent!
      - +@isprivate: "0"
        commentid: "16702"
        comment_count: "33"
        attachid: "768"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2016-01-27 01:45:13 +0100
        thetext: |-
          Created attachment 768
          .besa minus .edf converted
      - +@isprivate: "0"
        commentid: "16703"
        comment_count: "34"
        who:
          +content: kla
          +@name: Kris Anderson
        bug_when: 2016-01-27 01:47:16 +0100
        thetext: |-
          Here are some results from comparing data obtained from a Nihon Kohden system in .besa and converted .edf format:

           - The median difference between waveforms is 0.00002uA. Max difference is 0.006uA. See histogram of differences attached. This is probably floating point error.
           - .edf file contains 1 extra channel, an annotations channel that does not exist in the .besa file
           - .edf file has some extra samples at the end of the file, in one case, 5363030 samples vs 5363000 samples. The extra samples are just flat with a DC offset.
      - +@isprivate: "0"
        commentid: "16704"
        comment_count: "35"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2016-01-27 10:03:22 +0100
        thetext: |-
          (In reply to Kris Anderson from comment #34)

          Hi Kris,

          Thanks for the great work. To me it seems that (besides for the documentation) that the issue can be closed. I am in a meeting with Harald (CC< from BESA) and have suggested him to also review and improve http://www.fieldtriptoolbox.org/getting_started/besa

          best
          Robert
      - +@isprivate: "0"
        commentid: "16706"
        comment_count: "36"
        who:
          +content: a.stolk8
          +@name: Arjen Stolk
        bug_when: 2016-01-28 06:25:06 +0100
        thetext: |-
          Excellent. Thanks in advance, Harald.
          Arjen
      - +@isprivate: "0"
        commentid: "20134"
        comment_count: "37"
        who:
          +content: r.oostenveld
          +@name: Robert Oostenveld
        bug_when: 2019-08-10 12:32:31 +0200
        thetext: "This closes a whole series of bugs that have been resolved (either FIXED/WONTFIX/INVALID) for quite some time. \n\nIf you disagree, please file a new issue on https://github.com/fieldtrip/fieldtrip/issues."
    attachment:
      - +@isobsolete: "0"
        +@ispatch: "0"
        +@isprivate: "0"
        attachid: "760"
        date: 2015-12-09 02:05:00 +0100
        delta_ts: 2015-12-09 02:05:34 +0100
        desc: Preliminary readbesa matlab function
        filename: readbesa.m
        type: text/plain
        size: "93941"
        attacher:
          +content: kla
          +@name: Kris Anderson
        data: REMOVED
      - +@isobsolete: "0"
        +@ispatch: "0"
        +@isprivate: "0"
        attachid: "768"
        date: 2016-01-27 01:45:00 +0100
        delta_ts: 2016-01-27 01:45:13 +0100
        desc: .besa minus .edf converted
        filename: besa-edf.jpg
        type: image/jpeg
        size: "74689"
        attacher:
          +content: kla
          +@name: Kris Anderson
        data: REMOVED
